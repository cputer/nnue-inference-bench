# native-cuda (placeholder)

CUDA kernels for NNUE inference.

Planned:
- first-layer sparse accumulator
- hidden layer matmuls (if not using Mind matmul)
- C ABI hooks callable from Mind runtime
